{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7247a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scienceplots  # noqa: F401\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from utils import read_metrics_file, z_score\n",
    "from utils.constants import EWM_ALPHA, METRICS, WINDOW_SIZE, Events, datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c412fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use([\"science\", \"nature\"])\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 12,\n",
    "        \"xtick.labelsize\": 12,\n",
    "        \"ytick.labelsize\": 12,\n",
    "        \"axes.labelsize\": 12,\n",
    "        \"legend.fontsize\": 12,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e9e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filename=\"calc_stats.log\",\n",
    "    filemode=\"w\",\n",
    ")\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "console.setFormatter(formatter)\n",
    "logging.getLogger().addHandler(console)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5954ce5",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988f189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "EVENT: Events = \"Forbush Decrease\"\n",
    "event_replace = EVENT.replace(\" \", \"\")\n",
    "EWM: bool = True  # Use EWM smoothing\n",
    "ewm_suffix = f\"-ewm_alpha_{EWM_ALPHA}\" if EWM_ALPHA and EWM else \"\"\n",
    "\n",
    "winsorize: float = 0.01  # Percentile for winsorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71750f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "station",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "index",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "lag_hours",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d2032237-fe2b-4a04-8cbd-8584c15a8303",
       "rows": [
        [
         "0",
         "2023-04-23",
         "SOPO",
         "entropy",
         "2023-04-23 17:59:00",
         "1.15"
        ],
        [
         "1",
         "2023-04-23",
         "SOPO",
         "sampen",
         "2023-04-23 01:06:00",
         "-15.733333333333333"
        ],
        [
         "2",
         "2023-04-23",
         "SOPO",
         "permutation_entropy",
         "2023-04-23 12:50:00",
         "-4.0"
        ],
        [
         "3",
         "2023-04-23",
         "SOPO",
         "shannon_entropy",
         "2023-04-23 02:06:00",
         "-14.733333333333333"
        ],
        [
         "4",
         "2023-04-23",
         "SOPO",
         "spectral_entropy",
         "2023-04-24 00:50:00",
         "8.0"
        ],
        [
         "5",
         "2023-04-23",
         "SOPO",
         "app_entropy",
         "2023-04-23 01:06:00",
         "-15.733333333333333"
        ],
        [
         "6",
         "2023-04-23",
         "SOPO",
         "hurst",
         "2023-04-23 01:14:00",
         "-15.6"
        ],
        [
         "7",
         "2023-04-23",
         "SOPO",
         "dfa",
         "2023-04-23 01:14:00",
         "-15.6"
        ],
        [
         "8",
         "2023-04-23",
         "SOPO",
         "mfhurst_b",
         "2023-04-23 05:28:00",
         "-11.366666666666667"
        ],
        [
         "9",
         "2023-04-23",
         "SOPO",
         "higuchi_fd",
         "2023-04-23 07:26:00",
         "-9.4"
        ],
        [
         "10",
         "2023-04-23",
         "SOPO",
         "katz_fd",
         "2023-04-23 02:17:00",
         "-14.55"
        ],
        [
         "11",
         "2023-04-23",
         "SOPO",
         "petrosian_fd",
         "2023-04-23 14:00:00",
         "-2.833333333333333"
        ],
        [
         "12",
         "2023-04-23",
         "SOPO",
         "lepel_ziv",
         "2023-04-23 01:44:00",
         "-15.1"
        ],
        [
         "13",
         "2023-04-23",
         "SOPO",
         "corr_dim",
         "2023-04-23 01:35:00",
         "-15.25"
        ],
        [
         "14",
         "2023-04-23",
         "SOPO",
         "value",
         "2023-04-23 01:19:00",
         "-15.516666666666667"
        ],
        [
         "15",
         "2023-04-23",
         "NEWK",
         "entropy",
         "2023-04-23 18:29:00",
         "-1.6833333333333331"
        ],
        [
         "16",
         "2023-04-23",
         "NEWK",
         "sampen",
         "2023-04-23 04:21:00",
         "-15.816666666666666"
        ],
        [
         "17",
         "2023-04-23",
         "NEWK",
         "permutation_entropy",
         "2023-04-23 18:47:00",
         "-1.3833333333333333"
        ],
        [
         "18",
         "2023-04-23",
         "NEWK",
         "shannon_entropy",
         "2023-04-23 07:45:00",
         "-12.416666666666666"
        ],
        [
         "19",
         "2023-04-23",
         "NEWK",
         "spectral_entropy",
         "2023-04-23 18:22:00",
         "-1.8"
        ],
        [
         "20",
         "2023-04-23",
         "NEWK",
         "app_entropy",
         "2023-04-23 03:19:00",
         "-16.85"
        ],
        [
         "21",
         "2023-04-23",
         "NEWK",
         "hurst",
         "2023-04-23 01:49:00",
         "-18.35"
        ],
        [
         "22",
         "2023-04-23",
         "NEWK",
         "dfa",
         "2023-04-23 12:57:00",
         "-7.216666666666667"
        ],
        [
         "23",
         "2023-04-23",
         "NEWK",
         "mfhurst_b",
         "2023-04-23 01:10:00",
         "-19.0"
        ],
        [
         "24",
         "2023-04-23",
         "NEWK",
         "higuchi_fd",
         "2023-04-23 02:40:00",
         "-17.5"
        ],
        [
         "25",
         "2023-04-23",
         "NEWK",
         "katz_fd",
         "2023-04-23 01:18:00",
         "-18.866666666666667"
        ],
        [
         "26",
         "2023-04-23",
         "NEWK",
         "petrosian_fd",
         "2023-04-23 19:38:00",
         "-0.5333333333333333"
        ],
        [
         "27",
         "2023-04-23",
         "NEWK",
         "lepel_ziv",
         "2023-04-23 01:07:00",
         "-19.05"
        ],
        [
         "28",
         "2023-04-23",
         "NEWK",
         "corr_dim",
         "2023-04-23 02:35:00",
         "-17.583333333333332"
        ],
        [
         "29",
         "2023-04-23",
         "NEWK",
         "value",
         "2023-04-23 02:10:00",
         "-18.0"
        ],
        [
         "30",
         "2023-04-23",
         "AATB",
         "entropy",
         "2023-04-24 04:10:00",
         "10.166666666666666"
        ],
        [
         "31",
         "2023-04-23",
         "AATB",
         "sampen",
         "2023-04-23 01:39:00",
         "-16.35"
        ],
        [
         "32",
         "2023-04-23",
         "AATB",
         "permutation_entropy",
         "2023-04-23 03:13:00",
         "-14.783333333333331"
        ],
        [
         "33",
         "2023-04-23",
         "AATB",
         "shannon_entropy",
         "2023-04-23 02:18:00",
         "-15.7"
        ],
        [
         "34",
         "2023-04-23",
         "AATB",
         "spectral_entropy",
         "2023-04-23 16:58:00",
         "-1.0333333333333334"
        ],
        [
         "35",
         "2023-04-23",
         "AATB",
         "app_entropy",
         "2023-04-23 01:08:00",
         "-16.866666666666667"
        ],
        [
         "36",
         "2023-04-23",
         "AATB",
         "hurst",
         "2023-04-23 03:44:00",
         "-14.266666666666667"
        ],
        [
         "37",
         "2023-04-23",
         "AATB",
         "dfa",
         "2023-04-23 03:37:00",
         "-14.383333333333333"
        ],
        [
         "38",
         "2023-04-23",
         "AATB",
         "mfhurst_b",
         "2023-04-23 01:13:00",
         "-16.783333333333335"
        ],
        [
         "39",
         "2023-04-23",
         "AATB",
         "higuchi_fd",
         "2023-04-23 04:31:00",
         "-13.483333333333333"
        ],
        [
         "40",
         "2023-04-23",
         "AATB",
         "katz_fd",
         "2023-04-23 02:43:00",
         "-15.283333333333331"
        ],
        [
         "41",
         "2023-04-23",
         "AATB",
         "petrosian_fd",
         "2023-04-23 17:51:00",
         "-0.15"
        ],
        [
         "42",
         "2023-04-23",
         "AATB",
         "lepel_ziv",
         "2023-04-23 01:51:00",
         "-16.15"
        ],
        [
         "43",
         "2023-04-23",
         "AATB",
         "corr_dim",
         "2023-04-23 01:44:00",
         "-16.266666666666666"
        ],
        [
         "44",
         "2023-04-23",
         "AATB",
         "value",
         "2023-04-23 02:09:00",
         "-15.85"
        ],
        [
         "45",
         "2023-04-23",
         "PWNK",
         "entropy",
         "2023-04-23 01:06:00",
         "-16.9"
        ],
        [
         "46",
         "2023-04-23",
         "PWNK",
         "sampen",
         "2023-04-23 01:10:00",
         "-16.833333333333332"
        ],
        [
         "47",
         "2023-04-23",
         "PWNK",
         "permutation_entropy",
         "2023-04-23 08:13:00",
         "-9.783333333333331"
        ],
        [
         "48",
         "2023-04-23",
         "PWNK",
         "shannon_entropy",
         "2023-04-23 03:59:00",
         "-14.016666666666667"
        ],
        [
         "49",
         "2023-04-23",
         "PWNK",
         "spectral_entropy",
         "2023-04-23 18:49:00",
         "0.8166666666666667"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 480
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station</th>\n",
       "      <th>metric</th>\n",
       "      <th>index</th>\n",
       "      <th>lag_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>SOPO</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2023-04-23 17:59:00</td>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>SOPO</td>\n",
       "      <td>sampen</td>\n",
       "      <td>2023-04-23 01:06:00</td>\n",
       "      <td>-15.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>SOPO</td>\n",
       "      <td>permutation_entropy</td>\n",
       "      <td>2023-04-23 12:50:00</td>\n",
       "      <td>-4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>SOPO</td>\n",
       "      <td>shannon_entropy</td>\n",
       "      <td>2023-04-23 02:06:00</td>\n",
       "      <td>-14.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>SOPO</td>\n",
       "      <td>spectral_entropy</td>\n",
       "      <td>2023-04-24 00:50:00</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>APTY</td>\n",
       "      <td>katz_fd</td>\n",
       "      <td>2024-05-10 01:07:00</td>\n",
       "      <td>-16.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>APTY</td>\n",
       "      <td>petrosian_fd</td>\n",
       "      <td>2024-05-10 13:36:00</td>\n",
       "      <td>-4.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>APTY</td>\n",
       "      <td>lepel_ziv</td>\n",
       "      <td>2024-05-10 01:25:00</td>\n",
       "      <td>-16.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>APTY</td>\n",
       "      <td>corr_dim</td>\n",
       "      <td>2024-05-10 01:21:00</td>\n",
       "      <td>-16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>APTY</td>\n",
       "      <td>value</td>\n",
       "      <td>2024-05-10 01:22:00</td>\n",
       "      <td>-16.650000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date station               metric               index  lag_hours\n",
       "0    2023-04-23    SOPO              entropy 2023-04-23 17:59:00   1.150000\n",
       "1    2023-04-23    SOPO               sampen 2023-04-23 01:06:00 -15.733333\n",
       "2    2023-04-23    SOPO  permutation_entropy 2023-04-23 12:50:00  -4.000000\n",
       "3    2023-04-23    SOPO      shannon_entropy 2023-04-23 02:06:00 -14.733333\n",
       "4    2023-04-23    SOPO     spectral_entropy 2023-04-24 00:50:00   8.000000\n",
       "..          ...     ...                  ...                 ...        ...\n",
       "475  2024-05-10    APTY              katz_fd 2024-05-10 01:07:00 -16.900000\n",
       "476  2024-05-10    APTY         petrosian_fd 2024-05-10 13:36:00  -4.416667\n",
       "477  2024-05-10    APTY            lepel_ziv 2024-05-10 01:25:00 -16.600000\n",
       "478  2024-05-10    APTY             corr_dim 2024-05-10 01:21:00 -16.666667\n",
       "479  2024-05-10    APTY                value 2024-05-10 01:22:00 -16.650000\n",
       "\n",
       "[480 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df_path = Path(\n",
    "    f\"./data/{event_replace}/summary_derivatives{ewm_suffix}.csv\"\n",
    ")\n",
    "assert summary_df_path.exists()\n",
    "\n",
    "summary_df = pd.read_csv(summary_df_path, parse_dates=[\"index\"])\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613efb16",
   "metadata": {},
   "source": [
    "## Calculate stats\n",
    "\n",
    "Based on [tools/generate_results.py](./tools/generate_results.py) calcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9179a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_interval(\n",
    "    event: Events,\n",
    "    date: str,\n",
    "    station: str,\n",
    "    data: pd.DataFrame = None,\n",
    ") -> pd.DataFrame:\n",
    "    if data is None:\n",
    "        suffix = f\"-ewm_alpha_{EWM_ALPHA}\" if EWM_ALPHA and EWM else \"\"\n",
    "        data = read_metrics_file(\n",
    "            event,\n",
    "            date,\n",
    "            station,\n",
    "            WINDOW_SIZE,\n",
    "            datetime_cols={\"datetime\": None},\n",
    "            suffix=suffix,\n",
    "        ).set_index(\"datetime\")\n",
    "\n",
    "    data = data[(data[\"window_shape\"] == WINDOW_SIZE)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def process_derivatives(\n",
    "    event: Events,\n",
    "    date: str,\n",
    "    station: str,\n",
    "    winsorize_p: int = 0.01,\n",
    ") -> dict[str, pd.Series]:\n",
    "    assert 0 < winsorize_p < 0.5, \"Percentile must be between 0.0 and 0.5\"\n",
    "\n",
    "    data = read_metrics_file(\n",
    "        event,\n",
    "        date,\n",
    "        station,\n",
    "        WINDOW_SIZE,\n",
    "        datetime_cols={\"datetime\": None},\n",
    "        suffix=ewm_suffix,\n",
    "    ).set_index(\"datetime\")\n",
    "\n",
    "    # First filter by valid interval and then derivate\n",
    "    metrics_columns = list(filter(lambda col: col in METRICS, data.columns))\n",
    "    metrics_columns += [\"value\"]\n",
    "\n",
    "    valid_df = valid_interval(event, date, station, data)\n",
    "    interest_df = valid_df[metrics_columns].diff()\n",
    "\n",
    "    results: dict[str, pd.Series] = {}\n",
    "    for col in metrics_columns:\n",
    "        points = interest_df[col]\n",
    "        low, high = points.quantile([winsorize_p, 1 - winsorize_p])\n",
    "        points = np.clip(points, low, high)  # Winsorize\n",
    "        if len(points) < 0:\n",
    "            continue\n",
    "\n",
    "        results[col] = points\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9368ed1b",
   "metadata": {},
   "source": [
    "### Calculate new metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae12fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1000  # Bootstrap replicates\n",
    "block = 30  # Bootstrap block size (~30 mins)\n",
    "fdr_alpha = 0.05\n",
    "\n",
    "out_dir = Path(\"outputs\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig_out_dir = Path(\"figures\")\n",
    "fig_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "table_out_dir = Path(\"tables\")\n",
    "table_out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d375b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_block_bootstrap(x, block, B):\n",
    "    n = len(x)\n",
    "    if n == 0:\n",
    "        return np.empty((B, 0))\n",
    "\n",
    "    idx = np.arange(n)\n",
    "    out = np.empty((B, n), dtype=float)\n",
    "    for b in range(B):\n",
    "        cur = []\n",
    "        while len(cur) < n:\n",
    "            start = np.random.randint(0, n)\n",
    "            seg = idx[start : start + block]\n",
    "            if len(seg) < block:\n",
    "                seg = np.concatenate([seg, idx[: block - len(seg)]])\n",
    "            cur.extend(seg.tolist())\n",
    "        cur = np.array(cur[:n])\n",
    "        out[b] = x[cur]\n",
    "    return out\n",
    "\n",
    "\n",
    "def safe_corr_at_lag(a, b, lag, normalize=True):\n",
    "    if normalize:\n",
    "        a = z_score(np.asarray(a, dtype=float))\n",
    "        b = z_score(np.asarray(b, dtype=float))\n",
    "\n",
    "    if np.isnan(lag):\n",
    "        return np.nan\n",
    "    lag = int(lag)\n",
    "\n",
    "    if lag > 0:\n",
    "        a2 = a[:-lag]\n",
    "        b2 = b[lag:]\n",
    "    elif lag < 0:\n",
    "        a2 = a[-lag:]\n",
    "        b2 = b[:lag]\n",
    "    else:\n",
    "        a2 = a\n",
    "        b2 = b\n",
    "\n",
    "    if len(a2) < 5:\n",
    "        return np.nan\n",
    "\n",
    "    C = np.corrcoef(a2, b2)\n",
    "    return float(C[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60d85f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_event(date: str) -> pd.DataFrame:\n",
    "    def get_index_of_datetime(df: pd.Series, dt: pd.Timestamp) -> int:\n",
    "        tmp_df = df.reset_index()\n",
    "        if dt in tmp_df[\"datetime\"].values:\n",
    "            return tmp_df[tmp_df[\"datetime\"] == dt].index[0]\n",
    "\n",
    "        # Find the closest datetime\n",
    "        time_diffs = (tmp_df[\"datetime\"] - dt).abs()\n",
    "        return time_diffs.idxmin()\n",
    "\n",
    "    stations = (\n",
    "        summary_df[summary_df[\"date\"] == date][\"station\"].unique().tolist()\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    for station in stations:\n",
    "        logger.info(f\"  Processing station {station}...\")\n",
    "        derivatives = process_derivatives(EVENT, date, station, winsorize)\n",
    "\n",
    "        dx = derivatives.pop(\"value\")\n",
    "        original_onset_dt = pd.to_datetime(\n",
    "            datetimes[date][\"stations\"][station][0]\n",
    "        )\n",
    "        original_onset_idx = get_index_of_datetime(dx, original_onset_dt)\n",
    "        for metric, dy in derivatives.items():\n",
    "            logger.info(f\"    Processing metric {metric}...\")\n",
    "            # These results are the same calculated in summary_df\n",
    "            lag_dt = dy.idxmax()\n",
    "            lag_minutes = (lag_dt - original_onset_dt).total_seconds() / 60.0\n",
    "            lag_idx = get_index_of_datetime(dy, lag_dt)\n",
    "\n",
    "            # Bootstrap\n",
    "            # the same operations done in `tools/generate_results.py`\n",
    "            bs = moving_block_bootstrap(dy.values, block, B)\n",
    "            corr_obs = safe_corr_at_lag(dy.values, dx.values, lag_idx)\n",
    "\n",
    "            if np.isnan(corr_obs):\n",
    "                pval = 1.0\n",
    "            elif corr_obs >= 0:\n",
    "                pval = float(\n",
    "                    (\n",
    "                        np.apply_along_axis(\n",
    "                            lambda a: safe_corr_at_lag(a, dx, lag_idx), 1, bs\n",
    "                        )\n",
    "                        >= corr_obs\n",
    "                    ).mean()\n",
    "                )\n",
    "            else:\n",
    "                pval = float(\n",
    "                    (\n",
    "                        np.apply_along_axis(\n",
    "                            lambda a: safe_corr_at_lag(a, dx, lag_idx), 1, bs\n",
    "                        )\n",
    "                        <= corr_obs\n",
    "                    ).mean()\n",
    "                )\n",
    "\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"date\": date,\n",
    "                    \"station\": station.upper(),\n",
    "                    \"invariant\": metric,\n",
    "                    \"lag_minutes\": lag_minutes,\n",
    "                    \"lag_start_idx\": lag_idx,\n",
    "                    \"lag_start_dt\": lag_dt,\n",
    "                    \"corr_at_lag\": corr_obs,\n",
    "                    \"pval\": pval,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    res = pd.DataFrame(rows)\n",
    "    if res.empty:\n",
    "        return res\n",
    "\n",
    "    # FDR por invariante (global en el evento)\n",
    "    res[\"pval_adj\"] = np.nan\n",
    "    res[\"significant\"] = False\n",
    "    for inv in res[\"invariant\"].unique():\n",
    "        mask = res[\"invariant\"] == inv\n",
    "        p = res.loc[mask, \"pval\"].values\n",
    "        rej, p_adj, _, _ = multipletests(p, alpha=fdr_alpha, method=\"fdr_bh\")\n",
    "        res.loc[mask, \"pval_adj\"] = p_adj\n",
    "        res.loc[mask, \"significant\"] = rej.astype(bool)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74324f",
   "metadata": {},
   "source": [
    "### Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f60c2ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_global(df):\n",
    "    # agrega por invariante a través de eventos/estaciones\n",
    "    g = (\n",
    "        df.groupby(\"invariant\")\n",
    "        .agg(\n",
    "            median_lag=(\"lag_minutes\", \"median\"),\n",
    "            iqr_lag=(\n",
    "                \"lag_minutes\",\n",
    "                lambda x: np.subtract(*np.nanpercentile(x, [75, 25])),\n",
    "            ),\n",
    "            sig_pct=(\"significant\", lambda x: 100.0 * np.mean(x)),\n",
    "            n_stations=(\"station\", \"nunique\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    # score Rk\n",
    "    Lref = 120.0\n",
    "    w1, w2, w3 = 0.4, 0.3, 0.3\n",
    "    Nstn = df[\"station\"].nunique()\n",
    "    g[\"Rk\"] = (\n",
    "        w1 * (np.abs(g[\"median_lag\"]) / Lref).clip(0, 1)\n",
    "        + w2 * (1 - (g[\"iqr_lag\"] / Lref).clip(0, 1))\n",
    "        + w3 * (g[\"n_stations\"] / max(Nstn, 1))\n",
    "    )\n",
    "    g = g.sort_values(\"Rk\", ascending=False).reset_index(drop=True)\n",
    "    return g\n",
    "\n",
    "\n",
    "def summarize_by_event(df):\n",
    "    e = (\n",
    "        df.groupby([\"date\", \"invariant\"])\n",
    "        .agg(\n",
    "            median_lag=(\"lag_minutes\", \"median\"),\n",
    "            sig_pct=(\"significant\", lambda x: 100.0 * np.mean(x)),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    return e\n",
    "\n",
    "\n",
    "def tex_rank_table(g):\n",
    "    rows = []\n",
    "    for _, r in g.iterrows():\n",
    "        rows.append(\n",
    "            f\"{r['invariant'].replace('_', '\\\\_')} & {r['median_lag']:.1f} & {r['iqr_lag']:.1f} & {r['sig_pct']:.0f} & {r['Rk']:.2f} \\\\\\\\\"\n",
    "        )\n",
    "    body = \"\\n\".join(rows)\n",
    "    tex = (\n",
    "        r\"\"\"\n",
    "\\begin{table}[t]\n",
    "\\centering\n",
    "\\small\n",
    "\\caption{Global ranking of invariants by robustness score $R_k$ and median lead $\\widetilde{\\ell}_k$ (min; negative = precedes).}\n",
    "\\label{tab:rank_global}\n",
    "\\begin{tabular}{@{}l r r r r@{}}\n",
    "\\toprule\n",
    "\\textbf{Invariant} & $\\widetilde{\\ell}_k$ & IQR & Sig.\\ stations [\\%%] & $R_k$ \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "        + body\n",
    "        + r\"\"\"\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    )\n",
    "    return tex\n",
    "\n",
    "\n",
    "def tex_event_table(e, events):\n",
    "    # pivot inv × evento con (lag, sig)\n",
    "    frames = []\n",
    "    for ev in events:\n",
    "        sub = e[e[\"date\"] == ev][[\"invariant\", \"median_lag\", \"sig_pct\"]].copy()\n",
    "        sub.columns = [\"invariant\", f\"lag_{ev}\", f\"sig_{ev}\"]\n",
    "        frames.append(sub)\n",
    "    if not frames:\n",
    "        return r\"\\begin{table}[t]\\centering\\small\\caption{No data}\\label{tab:event_summary}\\begin{tabular}{@{}l@{}}\\toprule No data\\\\ \\bottomrule\\end{tabular}\\end{table}\"\n",
    "\n",
    "    M = frames[0]\n",
    "    for sub in frames[1:]:\n",
    "        M = M.merge(sub, on=\"invariant\", how=\"outer\")\n",
    "    M = M.fillna(np.nan)\n",
    "\n",
    "    # filas\n",
    "    rows_list = []\n",
    "    for _, r in M.iterrows():\n",
    "        parts = [r[\"invariant\"].replace(\"_\", r\"\\_\")]\n",
    "        for ev in events:\n",
    "            lag = r.get(f\"lag_{ev}\", np.nan)\n",
    "            sig = r.get(f\"sig_{ev}\", np.nan)\n",
    "            parts.append(f\"{lag:.1f} & {sig:.0f}\")\n",
    "        rows_list.append(\" & \".join(parts) + r\" \\\\\")\n",
    "    rows = \"\\n\".join(rows_list)\n",
    "\n",
    "    # encabezados y especificación de columnas\n",
    "    ev_heads = \" & \".join(\n",
    "        [r\"\\multicolumn{2}{c}{\\textbf{%s}}\" % ev for ev in events]\n",
    "    )\n",
    "    ev_sub = \" & \".join([r\"$\\widetilde{\\ell}_k$ & Sig.\\ [\\%%]\"] * len(events))\n",
    "    colspec = \"@{}l \" + \" \".join([\"r r\"] * len(events)) + \"@{}\"\n",
    "    endcol = 2 * len(events) + 1  # para \\cmidrule(lr){2-endcol}\n",
    "\n",
    "    # plantilla con % (no choca con llaves de LaTeX)\n",
    "    tex = r\"\"\"\\begin{table}[t]\n",
    "\\centering\n",
    "\\small\n",
    "\\caption{Per–event summary: median lead $\\widetilde{\\ell}_k$ (min; negative = precedes) and percent of stations with significant pre–onset change.}\n",
    "\\label{tab:event_summary}\n",
    "\\begin{tabular}{%s}\n",
    "\\toprule\n",
    " & %s \\\\\n",
    "\\cmidrule(lr){2-%d}\n",
    "\\textbf{Invariant} & %s \\\\\n",
    "\\midrule\n",
    "%s\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\" % (colspec, ev_heads, endcol, ev_sub, rows)\n",
    "    return tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a83a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_median_lead(e, events, outpath):\n",
    "    piv = e.pivot(\n",
    "        index=\"invariant\", columns=\"date\", values=\"median_lag\"\n",
    "    ).reindex(columns=events)\n",
    "    if piv.empty:\n",
    "        return\n",
    "\n",
    "    # Convert to hours for better readability\n",
    "    piv = piv / 60.0\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, max(4, 0.35 * len(piv))))\n",
    "    im = ax.imshow(piv.values, aspect=\"auto\")\n",
    "    ax.set_yticks(range(len(piv)))\n",
    "    ax.set_yticklabels([s.replace(\"_\", \" \") for s in piv.index])\n",
    "    ax.set_xticks(range(len(events)))\n",
    "    ax.set_xticklabels(events)\n",
    "    ax.set_title(\n",
    "        \"Median lead by invariant and event (min; negative = precedes)\"\n",
    "    )\n",
    "    for i in range(piv.shape[0]):\n",
    "        for j in range(piv.shape[1]):\n",
    "            v = piv.values[i, j]\n",
    "            if pd.notna(v):\n",
    "                ax.text(j, i, f\"{v:.0f}\", ha=\"center\", va=\"center\")\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    fig.tight_layout()\n",
    "    Path(outpath).parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(outpath, dpi=180)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def violin_lags(df, date, outpath):\n",
    "    sub = df[df[\"date\"] == date].copy()\n",
    "    if sub.empty:\n",
    "        return\n",
    "    invs = list(sub[\"invariant\"].unique())\n",
    "    data = [\n",
    "        sub.loc[sub[\"invariant\"] == k, \"lag_minutes\"].dropna().values\n",
    "        for k in invs\n",
    "    ]\n",
    "\n",
    "    # Convert to houyrs for better readability\n",
    "    data = list(map(lambda arr: arr / 60.0, data))\n",
    "\n",
    "    labels = [k.replace(\"_\", \" \") for k in invs]\n",
    "    fig, ax = plt.subplots(figsize=(10, max(4, 0.35 * len(labels))))\n",
    "    _ = ax.violinplot(data, showmedians=True, vert=False)\n",
    "    ax.set_yticks(np.arange(1, len(labels) + 1))\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_xlabel(\"lag* (hours; negative = precedes)\")\n",
    "    ax.set_title(f\"Station-wise lag distributions by invariant — {date}\")\n",
    "    fig.tight_layout()\n",
    "    Path(outpath).parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(outpath, dpi=180)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c0ce7",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9986002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    events = list(datetimes.keys())\n",
    "\n",
    "    all_res = []\n",
    "    for date in events:\n",
    "        logger.info(f\"Processing event {date}\")\n",
    "        res = process_event(date)\n",
    "        if res.empty:\n",
    "            logger.warning(f\"No results for {date}\")\n",
    "            continue\n",
    "        res.to_csv(out_dir / f\"station_results_{date}.csv\", index=False)\n",
    "        all_res.append(res)\n",
    "\n",
    "        # figuras por evento (violines)\n",
    "        violin_lags(\n",
    "            res, date, fig_out_dir / \"violins\" / f\"lag_violin_{date}.pdf\"\n",
    "        )\n",
    "\n",
    "    if not all_res:\n",
    "        logger.error(\"No events processed. Check column names in your CSVs.\")\n",
    "        return 1\n",
    "\n",
    "    df = pd.concat(all_res, ignore_index=True)\n",
    "    g = summarize_global(df)\n",
    "    e = summarize_by_event(df)\n",
    "    g.to_csv(out_dir / \"global_rank.csv\", index=False)\n",
    "    e.to_csv(out_dir / \"event_summary.csv\", index=False)\n",
    "\n",
    "    # tablas LaTeX\n",
    "    (table_out_dir / \"rank_global.tex\").write_text(tex_rank_table(g))\n",
    "    (table_out_dir / \"event_summary.tex\").write_text(tex_event_table(e, events))\n",
    "\n",
    "    # heatmap global\n",
    "    heatmap_median_lead(\n",
    "        e, events, fig_out_dir / \"heatmaps\" / \"median_lead_heatmap.png\"\n",
    "    )\n",
    "\n",
    "    logger.info(\"[OK] Results written to outputs/, tables/, figures/\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7970a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "SystemExit(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b423d224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
