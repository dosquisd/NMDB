{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4a162b",
   "metadata": {},
   "source": [
    "# Final Results\n",
    "\n",
    "Recalculate metrics and plot them, but done at many more stations for each datetime. Basically, a more robust version of [002](./002_calc_some_metrics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3593cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from random import sample\n",
    "from typing import Optional, TypedDict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from utils import (\n",
    "    calc_metrics,\n",
    "    load_data,\n",
    "    plot_metrics,\n",
    "    plot_metrics_one,\n",
    "    read_metrics_file,\n",
    ")\n",
    "from utils.constants import (\n",
    "    EWM_ALPHA,\n",
    "    NAN_THRESHOLD,\n",
    "    WINDOW_SIZE,\n",
    "    Events,\n",
    "    datetimes,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c51148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StationsToChoose(TypedDict):\n",
    "    \"\"\"\n",
    "    Structure for station selection data.\n",
    "\n",
    "    Attributes:\n",
    "        stations: list[str]. Available station names for random sampling.\n",
    "        num_sample: int. Number of stations to sample from the available list.\n",
    "    \"\"\"\n",
    "\n",
    "    stations: list[str]\n",
    "    num_sample: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac7bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT: Events = \"Forbush Decrease\"\n",
    "MAX_SAMPLES: int = 10  # Samples per date\n",
    "REPETITION: bool = False  # If True, it will repeat stations already calculated\n",
    "EWM: bool = False  # If True, it will calculate EWM metrics\n",
    "\n",
    "event_replace: str = EVENT.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2641e",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b489ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_stations(\n",
    "    df: pd.DataFrame, threshold: Optional[float] = None\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Drop stations (columns) that have a high ratio of NaN values.\n",
    "    The DataFrame is the one with the data of the stations (all.txt).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with the stations data.\n",
    "        threshold (Optional[float]): Ratio of NaN values to consider a station invalid.\n",
    "            If None, it will use the global NAN_THRESHOLD.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of valid station names (columns).\n",
    "    \"\"\"\n",
    "    if threshold is None:\n",
    "        threshold = NAN_THRESHOLD\n",
    "\n",
    "    nans_count = dict(\n",
    "        filter(\n",
    "            lambda x: x[1] > 0,\n",
    "            df.drop(columns=\"datetime\").isna().sum().to_dict().items(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    total = len(df)\n",
    "\n",
    "    # Drop columns (stations) that exceed a nan ratio threshold\n",
    "    stations = list(\n",
    "        df.drop(\n",
    "            columns=list(\n",
    "                filter(\n",
    "                    lambda station: nans_count[station] / total >= threshold,\n",
    "                    nans_count,\n",
    "                )\n",
    "            )\n",
    "        ).columns[1:]\n",
    "    )\n",
    "\n",
    "    return stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5822326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations: dict[str, list[str]] = {\n",
    "    date: get_valid_stations(\n",
    "        load_data(f\"./data/{event_replace}/{date}/all.txt\"),\n",
    "        threshold=NAN_THRESHOLD,\n",
    "    )\n",
    "    for date in datetimes\n",
    "}\n",
    "\n",
    "chosen_stations: dict[str, list[str]] = {\n",
    "    date: list(\n",
    "        map(\n",
    "            lambda filename: filename.name.strip().split(\"_\", 1)[0].upper(),\n",
    "            Path(f\"./data/{event_replace}/{date}\").glob(\"*.csv\"),\n",
    "        )\n",
    "    )\n",
    "    for date in datetimes\n",
    "}\n",
    "\n",
    "stations_to_choose: dict[str, StationsToChoose] = {\n",
    "    date: {\n",
    "        # Remove stations already calculated\n",
    "        # and those that are fixed to be calculated\n",
    "        \"stations\": list(\n",
    "            set(stations[date])\n",
    "            - set([date])\n",
    "            - set(datetimes[date][\"stations\"].keys())\n",
    "        ),\n",
    "        # Final number of samples to choose\n",
    "        \"num_sample\": num_samples\n",
    "        if (\n",
    "            num_samples := MAX_SAMPLES\n",
    "            - len(set([date]) | set(datetimes[date][\"stations\"].keys()))\n",
    "        )\n",
    "        > 0\n",
    "        else 0,\n",
    "    }\n",
    "    for date in datetimes\n",
    "}\n",
    "\n",
    "# Without repetition of stations already calculated\n",
    "plot_stations = {\n",
    "    date: sample(items[\"stations\"], k=items[\"num_sample\"])\n",
    "    + list(datetimes[date][\"stations\"].keys())\n",
    "    for date, items in stations_to_choose.items()\n",
    "}\n",
    "\n",
    "# Here is added repetition of stations already calculated (if needed)\n",
    "if REPETITION:\n",
    "    for date in plot_stations:\n",
    "        plot_stations[date].extend(chosen_stations[date])\n",
    "\n",
    "        # Drop duplicates\n",
    "        plot_stations[date] = list(set(plot_stations[date]))\n",
    "\n",
    "# Remove stations already calculated if repetition is False\n",
    "else:\n",
    "    plot_stations = {\n",
    "        date: list(set(items) - set(chosen_stations[date]))\n",
    "        for date, items in plot_stations.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80324d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, I'll use only one date\n",
    "plot_stations = dict(\n",
    "    filter(lambda x: x[0] == \"2024-05-10\", plot_stations.items())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae4968e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 minutes approximate to calculate all metrics with my pc\n",
    "suffix = f\"ewm_alpha_{EWM_ALPHA}\" if EWM_ALPHA and EWM else \"\"\n",
    "\n",
    "\n",
    "def prepare_df(path: str) -> pd.DataFrame:\n",
    "    df = load_data(path).set_index(\"datetime\")\n",
    "    return df.ewm(alpha=EWM_ALPHA).mean() if EWM_ALPHA and EWM else df\n",
    "\n",
    "\n",
    "arguments = [\n",
    "    (\n",
    "        prepare_df(f\"./data/{event_replace}/{date}/all.txt\"),\n",
    "        station,\n",
    "        date,\n",
    "        suffix,\n",
    "    )\n",
    "    for date, stations in plot_stations.items()\n",
    "    for station in stations\n",
    "]\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    results = pool.starmap(\n",
    "        calc_metrics,\n",
    "        arguments,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a61c8e",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "847902fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stations: dict[str, list[str]] = {\n",
    "    date: list(\n",
    "        set(\n",
    "            map(\n",
    "                # Get Station name from filename\n",
    "                lambda filename: filename.name.strip().split(\"_\", 1)[0].upper(),\n",
    "                Path(f\"./data/{event_replace}/{date}\").glob(\"*.csv\"),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    for date in datetimes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd202280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2023-04-23': 10, '2024-03-24': 11, '2024-05-10': 11}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nice! Expected output\n",
    "dict(map(lambda x: (x, len(plot_stations[x])), plot_stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f35ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mpl_worker_init():\n",
    "    import os  # noqa: E401\n",
    "    import tempfile\n",
    "\n",
    "    os.environ[\"MPLCONFIGDIR\"] = tempfile.mkdtemp(prefix=\"mplcache-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246ea766",
   "metadata": {},
   "outputs": [],
   "source": [
    "EWM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0e2043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, filter only one date\n",
    "plot_stations = dict(\n",
    "    filter(lambda x: x[0] == \"2024-03-24\", plot_stations.items())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0832522b",
   "metadata": {},
   "source": [
    "### Two differents plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36e9fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_wrapper(args_tuple: tuple[str, str, int]) -> None:\n",
    "    date, station, suffix = args_tuple\n",
    "\n",
    "    df = read_metrics_file(\n",
    "        event=event_replace,\n",
    "        date=date,\n",
    "        station=station,\n",
    "        window_size=WINDOW_SIZE,\n",
    "        datetime_cols={\"datetime\": \"\"},\n",
    "        suffix=f\"-ewm_alpha_{EWM_ALPHA}\" if EWM_ALPHA and EWM else \"\",\n",
    "    )\n",
    "\n",
    "    # Odd suffix: all metrics except \"lepel_ziv\"\n",
    "    if suffix % 2 == 1:\n",
    "        df = df.drop(columns=[\"lepel_ziv\"], errors=\"ignore\")\n",
    "        relevant_metrics = [\"*\"]\n",
    "\n",
    "    else:  # Even suffix: only \"lepel_ziv\"\n",
    "        relevant_metrics = [\"lepel_ziv\"]\n",
    "\n",
    "    if (\n",
    "        station in datetimes[date][\"stations\"]\n",
    "        and datetimes[date][\"stations\"][station]\n",
    "    ):\n",
    "        min_datetime, max_datetime = datetimes[date][\"stations\"][station]\n",
    "    else:\n",
    "        min_datetime, max_datetime = datetimes[date][\"bounds\"]\n",
    "\n",
    "    plot_metrics(\n",
    "        window_size=WINDOW_SIZE,\n",
    "        relevant_metrics=relevant_metrics,\n",
    "        df=df,\n",
    "        event=event_replace,\n",
    "        date=date,\n",
    "        station=station,\n",
    "        min_datetime=min_datetime,\n",
    "        max_datetime=max_datetime,\n",
    "        freq_hours=2,\n",
    "        save_format=\"pdf\",\n",
    "        suffix=str(suffix),\n",
    "        show=False,\n",
    "    )\n",
    "\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count(), initializer=_mpl_worker_init) as pool:\n",
    "    arguments_plot = [\n",
    "        (date, station, suffix + 2 if EWM else suffix)\n",
    "        for date, stations in plot_stations.items()\n",
    "        for station in stations\n",
    "        for suffix in [1, 2]\n",
    "    ]\n",
    "\n",
    "    pool.map(plot_metrics_wrapper, arguments_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc594f3",
   "metadata": {},
   "source": [
    "### One plot\n",
    "\n",
    "TODO: Change color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2db4daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_one_wrapper(args_tuple: tuple[str, str]) -> None:\n",
    "    date, station = args_tuple\n",
    "\n",
    "    df = read_metrics_file(\n",
    "        event=event_replace,\n",
    "        date=date,\n",
    "        station=station,\n",
    "        window_size=WINDOW_SIZE,\n",
    "        datetime_cols={\"datetime\": \"\"},\n",
    "        suffix=f\"-ewm_alpha_{EWM_ALPHA}\" if EWM_ALPHA and EWM else \"\",\n",
    "    )\n",
    "\n",
    "    if (\n",
    "        station in datetimes[date][\"stations\"]\n",
    "        and datetimes[date][\"stations\"][station]\n",
    "    ):\n",
    "        min_datetime, max_datetime = datetimes[date][\"stations\"][station]\n",
    "    else:\n",
    "        min_datetime, max_datetime = datetimes[date][\"bounds\"]\n",
    "\n",
    "    plot_metrics_one(\n",
    "        window_size=WINDOW_SIZE,\n",
    "        relevant_metrics=None,\n",
    "        df=df,\n",
    "        event=event_replace,\n",
    "        date=date,\n",
    "        station=station,\n",
    "        min_datetime=min_datetime,\n",
    "        max_datetime=max_datetime,\n",
    "        freq_hours=2,\n",
    "        save_format=\"pdf\",\n",
    "        show=False,\n",
    "    )\n",
    "\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count(), initializer=_mpl_worker_init) as pool:\n",
    "    arguments_plot = [\n",
    "        (date, station)\n",
    "        for date, stations in plot_stations.items()\n",
    "        for station in stations\n",
    "    ]\n",
    "\n",
    "    pool.map(plot_metrics_one_wrapper, arguments_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
