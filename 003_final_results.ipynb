{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4a162b",
   "metadata": {},
   "source": [
    "# Final Results\n",
    "\n",
    "Recalculate metrics and plot them, but done at many more stations for each datetime. Basically, a more robust version of [002](./002_calc_some_metrics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3593cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from typing import TypedDict, Optional\n",
    "\n",
    "from random import sample\n",
    "from utils.constants import WINDOW_SIZE, Events, NAN_THRESHOLD\n",
    "from utils import load_data, calc_metrics, plot_metrics, read_metrics_file\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c51148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateEventsInfo(TypedDict):\n",
    "    \"\"\"\n",
    "    Information about the event date.\n",
    "\n",
    "    Attributes:\n",
    "        bounds: list[str] The start and end bounds of the event date.\n",
    "        freq: str The frequency of the data for the event date.\n",
    "        stations: list[str] The list of relevant stations for the event date.\n",
    "    \"\"\"\n",
    "\n",
    "    bounds: list[str]\n",
    "    freq: str\n",
    "    stations: list[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac7bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT: Events = \"Forbush Decrease\"\n",
    "MAX_SAMPLES: int = 10  # Samples per date\n",
    "REPETITION: bool = True  # If True, it will repeat stations already calculated\n",
    "\n",
    "event_replace: str = EVENT.replace(\" \", \"\")\n",
    "\n",
    "# Relevant dates for the event\n",
    "# Stations lists are only examples where the event was clear;\n",
    "# can be modify them as needed\n",
    "datetimes: dict[str, DateEventsInfo] = {\n",
    "    \"2023-04-23\": {\n",
    "        \"bounds\": [\"2023-04-23 23:00:00\", \"2023-04-24 06:00:00\"],\n",
    "        \"freq\": \"1h\",\n",
    "        \"stations\": [\n",
    "            \"AATB\",\n",
    "            \"APTY\",\n",
    "            \"IRK2\",\n",
    "            \"LMKS\",\n",
    "            \"NEWK\",\n",
    "            \"NAIN\",\n",
    "            \"SOPO\",\n",
    "        ],\n",
    "    },\n",
    "    \"2024-03-24\": {\n",
    "        \"bounds\": [\"2024-03-24 14:00:00\", \"2024-03-25 04:30:00\"],\n",
    "        \"freq\": \"90min\",\n",
    "        \"stations\": [\n",
    "            \"APTY\",\n",
    "            \"DOMC\",\n",
    "            \"INVK\",\n",
    "            \"JUNG1\",\n",
    "            \"KIEL2\",\n",
    "            \"LMKS\",\n",
    "            \"MWSN\",\n",
    "            \"NEWK\",\n",
    "            \"MXCO\",\n",
    "            \"OULU\",\n",
    "            # TXBY, YKTK\n",
    "        ],\n",
    "    },\n",
    "    \"2024-05-10\": {\n",
    "        \"bounds\": [\"2024-05-10 18:00:00\", \"2024-05-11 01:00:00\"],\n",
    "        \"freq\": \"1h\",\n",
    "        \"stations\": [\n",
    "            \"APTY\",\n",
    "            \"DOMB\",\n",
    "            \"DOMC\",\n",
    "            \"INVK\",\n",
    "            \"IRK3\",\n",
    "            \"JBGO\",\n",
    "            \"KERG\",\n",
    "            \"KIEL2\",\n",
    "            \"LMKS\",\n",
    "            \"MWSN\",\n",
    "            # SOPB, PWNK, SOPO, TERA, THUL, TXBY, YKTK\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2641e",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b489ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_stations(\n",
    "    df: pd.DataFrame, threshold: Optional[float] = None\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Drop stations (columns) that have a high ratio of NaN values.\n",
    "    The DataFrame is the one with the data of the stations (all.txt).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with the stations data.\n",
    "        threshold (Optional[float]): Ratio of NaN values to consider a station invalid.\n",
    "            If None, it will use the global NAN_THRESHOLD.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of valid station names (columns).\n",
    "    \"\"\"\n",
    "    if threshold is None:\n",
    "        threshold = NAN_THRESHOLD\n",
    "\n",
    "    nans_count = dict(\n",
    "        filter(\n",
    "            lambda x: x[1] > 0,\n",
    "            df.drop(columns=\"datetime\").isna().sum().to_dict().items(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    total = len(df)\n",
    "\n",
    "    # Drop columns (stations) that superates a nan ratio threshold\n",
    "    stations = list(\n",
    "        df.drop(\n",
    "            columns=list(\n",
    "                filter(\n",
    "                    lambda station: nans_count[station] / total >= threshold, nans_count\n",
    "                )\n",
    "            )\n",
    "        ).columns[1:]\n",
    "    )\n",
    "\n",
    "    return stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5822326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StationsToChoose(TypedDict):\n",
    "    stations: list[str]\n",
    "    num_sample: int\n",
    "\n",
    "\n",
    "stations: dict[str, list[str]] = {\n",
    "    date: get_valid_stations(\n",
    "        load_data(f\"./data/{event_replace}/{date}/all.txt\"),\n",
    "        threshold=NAN_THRESHOLD,\n",
    "    )\n",
    "    for date in datetimes\n",
    "}\n",
    "\n",
    "choosen_stations: dict[str, list[str]] = {\n",
    "    date: list(\n",
    "        map(\n",
    "            lambda filename: filename.name.strip().split(\"_\", 1)[0].upper(),\n",
    "            Path(f\"./data/{event_replace}/{date}\").glob(\"*.csv\"),\n",
    "        )\n",
    "    )\n",
    "    for date in datetimes\n",
    "}\n",
    "\n",
    "stations_to_choose: dict[str, StationsToChoose] = {\n",
    "    date: {\n",
    "        # Remove stations already calculated\n",
    "        # and those that are fixed to be calculated\n",
    "        \"stations\": list(\n",
    "            set(stations[date])\n",
    "            - set(choosen_stations[date])\n",
    "            - set(datetimes[date][\"stations\"])\n",
    "        ),\n",
    "        # Final number of samples to choose\n",
    "        \"num_sample\": num_samples\n",
    "        if (\n",
    "            num_samples := MAX_SAMPLES\n",
    "            - len(choosen_stations[date])\n",
    "            - len(datetimes[date][\"stations\"])\n",
    "        )\n",
    "        > 0\n",
    "        else 0,\n",
    "    }\n",
    "    for date in datetimes\n",
    "}\n",
    "\n",
    "# Without repetition of stations already calculated\n",
    "plot_stations = {\n",
    "    date: sample(items[\"stations\"], k=items[\"num_sample\"]) + datetimes[date][\"stations\"]\n",
    "    for date, items in stations_to_choose.items()\n",
    "}\n",
    "\n",
    "# Here is added repetition of stations already calculated (if needed)\n",
    "if REPETITION:\n",
    "    for date in plot_stations:\n",
    "        plot_stations[date].extend(choosen_stations[date])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae4968e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 minutes approximate to calculate all metrics with my pc\n",
    "arguments = [\n",
    "    (\n",
    "        load_data(f\"./data/{event_replace}/{date}/all.txt\").set_index(\"datetime\"),\n",
    "        station,\n",
    "        date,\n",
    "    )\n",
    "    for date, stations in plot_stations.items()\n",
    "    for station in stations\n",
    "]\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    results = pool.starmap(\n",
    "        calc_metrics,\n",
    "        arguments,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a61c8e",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "847902fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stations: dict[str, list[str]] = {\n",
    "    date: list(\n",
    "        map(\n",
    "            # Get Station name from filename\n",
    "            lambda filename: filename.name.strip().split(\"_\", 1)[0].upper(),\n",
    "            Path(f\"./data/{event_replace}/{date}\").glob(\"*.csv\"),\n",
    "        )\n",
    "    )\n",
    "    for date in datetimes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36e9fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_wrapper(args_tuple) -> None:\n",
    "    date, station, suffix = args_tuple\n",
    "\n",
    "    df = read_metrics_file(\n",
    "        event=event_replace,\n",
    "        date=date,\n",
    "        station=station,\n",
    "        window_size=WINDOW_SIZE,\n",
    "        datetime_cols={\"datetime\": \"\"},\n",
    "    )\n",
    "\n",
    "    if suffix == 1:\n",
    "        df = df.drop(columns=[\"lepel_ziv\"], errors=\"ignore\")\n",
    "        relevant_metrics = [\"*\"]\n",
    "    else:\n",
    "        relevant_metrics = [\"lepel_ziv\"]\n",
    "\n",
    "    freq_date_range = datetimes[date][\"freq\"]\n",
    "\n",
    "    plot_metrics(\n",
    "        window_size=WINDOW_SIZE,\n",
    "        relevant_metrics=relevant_metrics,\n",
    "        df=df,\n",
    "        event=event_replace,\n",
    "        date=date,\n",
    "        station=station,\n",
    "        min_datetime=datetimes[date][\"bounds\"][0],\n",
    "        max_datetime=datetimes[date][\"bounds\"][1],\n",
    "        freq_date_range=freq_date_range,\n",
    "        save_format=\"pdf\",\n",
    "        suffix=str(suffix),\n",
    "        show=False\n",
    "    )\n",
    "\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    arguments_plot = [\n",
    "        (date, station, suffix)\n",
    "        for date, stations in plot_stations.items()\n",
    "        for station in stations\n",
    "        for suffix in [1, 2]\n",
    "    ]\n",
    "\n",
    "    pool.map(plot_metrics_wrapper, arguments_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72dc48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
