{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4a162b",
   "metadata": {},
   "source": [
    "# Final Results\n",
    "\n",
    "Recalculate metrics and plot them, but done at many more stations for each datetime. Basically, a more robust version of [002](./002_calc_some_metrics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3593cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from typing import TypedDict, Optional\n",
    "\n",
    "from random import sample\n",
    "from utils.constants import WINDOW_SIZE, Events, NAN_THRESHOLD, EWM_ALPHA\n",
    "from utils import (\n",
    "    load_data,\n",
    "    calc_metrics,\n",
    "    plot_metrics,\n",
    "    read_metrics_file,\n",
    "    plot_metrics_one,\n",
    ")\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c51148",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatetimeBounds = list[str, str]\n",
    "\n",
    "\n",
    "class DateEventsInfo(TypedDict):\n",
    "    \"\"\"\n",
    "    Information about the event date.\n",
    "\n",
    "    Attributes:\n",
    "        bounds: list[DatetimeBounds]. The start and end bounds of the event date. Generally,\n",
    "                the bounds are the same for all stations.\n",
    "        freq: str. The frequency of the data for the event date.\n",
    "        stations: dict[str, Optional[DatetimeBounds]]. The list of relevant stations\n",
    "                  for the event date.\n",
    "    \"\"\"\n",
    "\n",
    "    bounds: list[DatetimeBounds]\n",
    "    freq: str\n",
    "    stations: dict[str, Optional[DatetimeBounds]]\n",
    "\n",
    "\n",
    "class StationsToChoose(TypedDict):\n",
    "    \"\"\"\n",
    "    Structure for station selection data.\n",
    "\n",
    "    Attributes:\n",
    "        stations: list[str]. Available station names for random sampling.\n",
    "        num_sample: int. Number of stations to sample from the available list.\n",
    "    \"\"\"\n",
    "\n",
    "    stations: list[str]\n",
    "    num_sample: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac7bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT: Events = \"Forbush Decrease\"\n",
    "MAX_SAMPLES: int = 10  # Samples per date\n",
    "REPETITION: bool = True  # If True, it will repeat stations already calculated\n",
    "EWM: bool = True  # If True, it will calculate EWM metrics\n",
    "\n",
    "event_replace: str = EVENT.replace(\" \", \"\")\n",
    "\n",
    "# Relevant dates for the event\n",
    "# Stations lists are only examples where the event was clear;\n",
    "# can be modify them as needed\n",
    "# TODO: Fix datetime event for each station\n",
    "datetimes: dict[str, Optional[DateEventsInfo]] = {\n",
    "    \"2023-04-23\": {\n",
    "        \"bounds\": [\"2023-04-23 23:00:00\", \"2023-04-24 06:00:00\"],\n",
    "        \"freq\": \"1h\",\n",
    "        \"stations\": {\n",
    "            \"AATB\": None,\n",
    "            \"APTY\": None,\n",
    "            \"IRK2\": None,\n",
    "            \"LMKS\": None,\n",
    "            \"NEWK\": None,\n",
    "            \"NAIN\": None,\n",
    "            \"SOPO\": None,\n",
    "        },\n",
    "    },\n",
    "    \"2024-03-24\": {\n",
    "        \"bounds\": [\"2024-03-24 14:00:00\", \"2024-03-25 04:30:00\"],\n",
    "        \"freq\": \"90min\",\n",
    "        \"stations\": {\n",
    "            \"APTY\": None,\n",
    "            \"DOMC\": None,\n",
    "            \"INVK\": None,\n",
    "            \"JUNG1\": None,\n",
    "            \"KIEL2\": None,\n",
    "            \"LMKS\": None,\n",
    "            \"MWSN\": None,\n",
    "            \"NEWK\": None,\n",
    "            \"MXCO\": None,\n",
    "            \"OULU\": None,\n",
    "            # TXBY, YKTK\n",
    "        },\n",
    "    },\n",
    "    \"2024-05-10\": {\n",
    "        \"bounds\": [\"2024-05-10 18:00:00\", \"2024-05-11 01:00:00\"],\n",
    "        \"freq\": \"1h\",\n",
    "        \"stations\": {\n",
    "            \"APTY\": None,\n",
    "            \"DOMB\": None,\n",
    "            \"DOMC\": None,\n",
    "            \"INVK\": None,\n",
    "            \"IRK3\": None,\n",
    "            \"JBGO\": None,\n",
    "            \"KERG\": None,\n",
    "            \"KIEL2\": None,\n",
    "            \"LMKS\": None,\n",
    "            \"MWSN\": None,\n",
    "            # SOPB, PWNK, SOPO, TERA, THUL, TXBY, YKTK\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2641e",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b489ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_stations(\n",
    "    df: pd.DataFrame, threshold: Optional[float] = None\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Drop stations (columns) that have a high ratio of NaN values.\n",
    "    The DataFrame is the one with the data of the stations (all.txt).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with the stations data.\n",
    "        threshold (Optional[float]): Ratio of NaN values to consider a station invalid.\n",
    "            If None, it will use the global NAN_THRESHOLD.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of valid station names (columns).\n",
    "    \"\"\"\n",
    "    if threshold is None:\n",
    "        threshold = NAN_THRESHOLD\n",
    "\n",
    "    nans_count = dict(\n",
    "        filter(\n",
    "            lambda x: x[1] > 0,\n",
    "            df.drop(columns=\"datetime\").isna().sum().to_dict().items(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    total = len(df)\n",
    "\n",
    "    # Drop columns (stations) that superates a nan ratio threshold\n",
    "    stations = list(\n",
    "        df.drop(\n",
    "            columns=list(\n",
    "                filter(\n",
    "                    lambda station: nans_count[station] / total >= threshold, nans_count\n",
    "                )\n",
    "            )\n",
    "        ).columns[1:]\n",
    "    )\n",
    "\n",
    "    return stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5822326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations: dict[str, list[str]] = {\n",
    "    date: get_valid_stations(\n",
    "        load_data(f\"./data/{event_replace}/{date}/all.txt\"),\n",
    "        threshold=NAN_THRESHOLD,\n",
    "    )\n",
    "    for date in datetimes\n",
    "}\n",
    "\n",
    "choosen_stations: dict[str, list[str]] = {\n",
    "    date: list(\n",
    "        map(\n",
    "            lambda filename: filename.name.strip().split(\"_\", 1)[0].upper(),\n",
    "            Path(f\"./data/{event_replace}/{date}\").glob(\"*.csv\"),\n",
    "        )\n",
    "    )\n",
    "    for date in datetimes\n",
    "}\n",
    "\n",
    "stations_to_choose: dict[str, StationsToChoose] = {\n",
    "    date: {\n",
    "        # Remove stations already calculated\n",
    "        # and those that are fixed to be calculated\n",
    "        \"stations\": list(\n",
    "            set(stations[date])\n",
    "            - set(choosen_stations[date])\n",
    "            - set(datetimes[date][\"stations\"].keys())\n",
    "        ),\n",
    "        # Final number of samples to choose\n",
    "        \"num_sample\": num_samples\n",
    "        if (\n",
    "            num_samples := MAX_SAMPLES\n",
    "            - len(choosen_stations[date])\n",
    "            - len(datetimes[date][\"stations\"].keys())\n",
    "        )\n",
    "        > 0\n",
    "        else 0,\n",
    "    }\n",
    "    for date in datetimes\n",
    "}\n",
    "\n",
    "# Without repetition of stations already calculated\n",
    "plot_stations = {\n",
    "    date: sample(items[\"stations\"], k=items[\"num_sample\"])\n",
    "    + list(datetimes[date][\"stations\"].keys())\n",
    "    for date, items in stations_to_choose.items()\n",
    "}\n",
    "\n",
    "# Here is added repetition of stations already calculated (if needed)\n",
    "if REPETITION:\n",
    "    for date in plot_stations:\n",
    "        plot_stations[date].extend(choosen_stations[date])\n",
    "\n",
    "        # Drop duplicates\n",
    "        plot_stations[date] = list(set(plot_stations[date]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae4968e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 minutes approximate to calculate all metrics with my pc\n",
    "suffix = f\"ewm_alpha_{EWM_ALPHA}\" if EWM_ALPHA else \"\"\n",
    "\n",
    "\n",
    "def prepare_df(path: str) -> pd.DataFrame:\n",
    "    df = load_data(path).set_index(\"datetime\")\n",
    "    return df.ewm(alpha=EWM_ALPHA).mean() if EWM_ALPHA and EWM else df\n",
    "\n",
    "\n",
    "arguments = [\n",
    "    (\n",
    "        prepare_df(f\"./data/{event_replace}/{date}/all.txt\"),\n",
    "        station,\n",
    "        date,\n",
    "        suffix,\n",
    "    )\n",
    "    for date, stations in plot_stations.items()\n",
    "    for station in stations\n",
    "]\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    results = pool.starmap(\n",
    "        calc_metrics,\n",
    "        arguments,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a61c8e",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847902fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stations: dict[str, list[str]] = {\n",
    "    date: list(\n",
    "        set(\n",
    "            map(\n",
    "                # Get Station name from filename\n",
    "                lambda filename: filename.name.strip().split(\"_\", 1)[0].upper(),\n",
    "                Path(f\"./data/{event_replace}/{date}\").glob(\"*.csv\"),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    for date in datetimes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd202280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2023-04-23': 10, '2024-03-24': 11, '2024-05-10': 11}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nice! Expected output\n",
    "dict(map(lambda x: (x, len(plot_stations[x])), plot_stations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0832522b",
   "metadata": {},
   "source": [
    "### Two differents plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36e9fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_wrapper(args_tuple: tuple[str, str, int]) -> None:\n",
    "    date, station, suffix = args_tuple\n",
    "\n",
    "    df = read_metrics_file(\n",
    "        event=event_replace,\n",
    "        date=date,\n",
    "        station=station,\n",
    "        window_size=WINDOW_SIZE,\n",
    "        datetime_cols={\"datetime\": \"\"},\n",
    "        suffix=f\"-ewm_alpha_{EWM_ALPHA}\" if EWM_ALPHA and EWM else \"\",\n",
    "    )\n",
    "\n",
    "    # Odd suffix: all metrics except \"lepel_ziv\"\n",
    "    if suffix % 2 == 1:\n",
    "        df = df.drop(columns=[\"lepel_ziv\"], errors=\"ignore\")\n",
    "        relevant_metrics = [\"*\"]\n",
    "\n",
    "    else:  # Even suffix: only \"lepel_ziv\"\n",
    "        relevant_metrics = [\"lepel_ziv\"]\n",
    "\n",
    "    if station in datetimes[date][\"stations\"] and datetimes[date][\"stations\"][station]:\n",
    "        min_datetime, max_datetime = datetimes[date][\"stations\"][station]\n",
    "    else:\n",
    "        min_datetime, max_datetime = datetimes[date][\"bounds\"]\n",
    "\n",
    "    plot_metrics(\n",
    "        window_size=WINDOW_SIZE,\n",
    "        relevant_metrics=relevant_metrics,\n",
    "        df=df,\n",
    "        event=event_replace,\n",
    "        date=date,\n",
    "        station=station,\n",
    "        min_datetime=min_datetime,\n",
    "        max_datetime=max_datetime,\n",
    "        freq_date_range=datetimes[date][\"freq\"],\n",
    "        save_format=\"pdf\",\n",
    "        suffix=str(suffix),\n",
    "        show=False,\n",
    "    )\n",
    "\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    arguments_plot = [\n",
    "        (date, station, suffix + 2 if EWM else suffix)\n",
    "        for date, stations in plot_stations.items()\n",
    "        for station in stations\n",
    "        for suffix in [1, 2]\n",
    "    ]\n",
    "\n",
    "    pool.map(plot_metrics_wrapper, arguments_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc594f3",
   "metadata": {},
   "source": [
    "### One plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2db4daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_one_wrapper(args_tuple: tuple[str, str]) -> None:\n",
    "    date, station = args_tuple\n",
    "\n",
    "    df = read_metrics_file(\n",
    "        event=event_replace,\n",
    "        date=date,\n",
    "        station=station,\n",
    "        window_size=WINDOW_SIZE,\n",
    "        datetime_cols={\"datetime\": \"\"},\n",
    "        suffix=f\"-ewm_alpha_{EWM_ALPHA}\" if EWM_ALPHA and EWM else \"\",\n",
    "    )\n",
    "\n",
    "    if station in datetimes[date][\"stations\"] and datetimes[date][\"stations\"][station]:\n",
    "        min_datetime, max_datetime = datetimes[date][\"stations\"][station]\n",
    "    else:\n",
    "        min_datetime, max_datetime = datetimes[date][\"bounds\"]\n",
    "\n",
    "    display(df.head())\n",
    "\n",
    "    plot_metrics_one(\n",
    "        window_size=WINDOW_SIZE,\n",
    "        relevant_metrics=None,\n",
    "        df=df,\n",
    "        event=event_replace,\n",
    "        date=date,\n",
    "        station=station,\n",
    "        min_datetime=min_datetime,\n",
    "        max_datetime=max_datetime,\n",
    "        freq_date_range=datetimes[date][\"freq\"],\n",
    "        rotation_xticks=60,\n",
    "        save_format=\"pdf\",\n",
    "        show=False,\n",
    "    )\n",
    "\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    arguments_plot = [\n",
    "        (date, station)\n",
    "        for date, stations in plot_stations.items()\n",
    "        for station in stations\n",
    "    ]\n",
    "\n",
    "    pool.map(plot_metrics_one_wrapper, arguments_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3a4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
